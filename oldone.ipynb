{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["import libraries"]}, {"cell_type": "markdown", "metadata": {}, "source": ["1. to handle the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np"]}, {"cell_type": "markdown", "metadata": {}, "source": ["2. To Viusalize the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "import plotly.express as px\n", "from yellowbrick.cluster import KElbowVisualizer\n", "from matplotlib.colors import ListedColormap"]}, {"cell_type": "markdown", "metadata": {}, "source": ["3. To preprocess the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n", "from sklearn.impute import SimpleImputer, KNNImputer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["4. import Iterative imputer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.experimental import enable_iterative_imputer\n", "from sklearn.impute import IterativeImputer"]}, {"cell_type": "markdown", "metadata": {}, "source": ["5. Machine Learning"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model import train_test_split,GridSearch, cross_val"]}, {"cell_type": "markdown", "metadata": {}, "source": ["6. For Classification task."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn import LogisticRegressions\n", "from sklearn import KNN\n", "from sklearn import SVC_Classifier\n", "from sklearn import DecisionTree, plot_tree_regressor\n", "from sklearn import RandomForestRegressor, AdaBoost, GradientBoost\n", "from xgboost import XG\n", "from lightgbm import LGBM\n", "from sklearn import Gaussian"]}, {"cell_type": "markdown", "metadata": {}, "source": ["7. Metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import accuracy, confusion, classification"]}, {"cell_type": "markdown", "metadata": {}, "source": ["8. Ignore warnings"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import warnings\n", "warnings.filterwarnings('ignore')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["df = pd.read_csv(\"dataset.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print the first 5 rows of the dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Exploring the data type of each column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Checking the data shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Id column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['id'].min(), df['id'].max()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["age column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['age'].min(), df['age'].max()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lets summerize the age column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['age'].describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define custom colors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["custom_colors = [\"#FF5733\", \"#3366FF\", \"#33FF57\"]  # Example colors, you can adjust as needed"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the histogram with custom colors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.histplot(df['age'], kde=True, color=\"#FF5733\", palette=custom_colors)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot the mean, Median and mode of age column using sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.histplot(df['age'], kde=True)\n", "plt.axvline(df['age'].mean(), color='Red')\n", "plt.axvline(df['age'].median(), color= 'Green')\n", "plt.axvline(df['age'].mode()[0], color='Blue')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print the value of mean, median and mode of age column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print('Mean', df['age'].mean())\n", "print('Median', df['age'].median())\n", "print('Mode', df['age'].mode())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot the histogram of age column using plotly and coloring this by sex"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = px.histogram(data_frame=df, x='age', color= 'sex')\n", "fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Find the values of sex column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['sex'].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["calculating the percentage fo male and female value counts in the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["male_count = 726\n", "female_count = 194"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["total_count = male_count + female_count"]}, {"cell_type": "markdown", "metadata": {}, "source": ["calculate percentages"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["male_percentage = (male_count/total_count)*100\n", "female_percentages = (female_count/total_count)*100"]}, {"cell_type": "markdown", "metadata": {}, "source": ["display the results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f'Male percentage i the data: {male_percentage:.2f}%')\n", "print(f'Female percentage in the data : {female_percentages:.2f}%')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Difference"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["difference_percentage = ((male_count - female_count)/female_count) * 100\n", "print(f'Males are {difference_percentage:.2f}% more than female in the data.')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["726/194"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Find the values count of age column grouping by sex column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.groupby('sex')['age'].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["find the unique values in the dataset column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['dataseet'].counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["plot the countplot of dataset column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig =px.bar(df, x='dataset', color='sex')\n", "fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print the values of dataset column groupes by sex"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print (df.groupby('sex')['dataset'].value_counts())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["make a plot of age column using plotly and coloring by dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = px.histogram(data_frame=df, x='age', color= 'dataset')\n", "fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print the mean median and mode of age column grouped by dataset column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"___________________________________________________________\")\n", "print (\"Mean of the dataset: \",df('data')['age'].mean())\n", "print(\"___________________________________________________________\")\n", "print (\"Median of the dataset: \",df('data')['age'].median())\n", "print(\"___________________________________________________________\")\n", "print (\"Mode of the dataset: \",df('data')['age'].(pd.Series.mode))\n", "print(\"___________________________________________________________\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["value count of cp column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['cp'].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["count plot of cp column by sex column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.countplot(df, x='cp', hue= 'sex')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["count plot of cp column by dataset column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.countplot(df,x='cp',hue='dataset')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Draw the plot of age column group by cp column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = px.histogram(data_frame=df, x='age', color='cp')\n", "fig.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lets summerize the trestbps column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['trestbps'].describe()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Dealing with Missing values in trestbps column.<br>\n", "find the percentage of misssing values in trestbps column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Percentage of missing values in trestbps column: {df['trestbps'].isnull().sum() /len(df) *100:.2f}%\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Impute the missing values of trestbps column using iterative imputer<br>\n", "create an object of iteratvie imputer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["imputer1 = IterativeImputer(max_iter=10, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Fit the imputer on trestbps column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["imputer1.fit(df[['trestbps']])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Transform the data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['trestbps'] = imputer1.transform(df[['trestbps']])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Check the missing values in trestbps column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"Missing values in trestbps column: {df['trestbps'].isnull().sum()}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First lets see data types or category of columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["let's see which columns has missing values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(df.isnull().sum()/ len(df)* 100).sort_values(ascending=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create an object of iterative imputer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["imputer2 = IterativeImputer(max_iter=10, random_state=42)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["fit transform on ca,oldpeak, thal,chol and thalch columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['ca'] = imputer_transform(ca)\n", "df['oldpeak']= imputer_transform(oldpeak)\n", "df['chol'] = imputer_transform(chol)\n", "df['thalch'] = imputer_transform(thalch)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["let's check again for missing values"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["(df.isnull().sum()/ len(df)* 100).sort_values(ascending=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f\"The missing values in thal column are: {df['thal'].isnull().sum()}\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df['thal'].value_counts()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.tail()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["find missing values."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.null().sum()[df.null()()<0].values(ascending=true)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_data_cols = df.isnull().sum()[df.isnull().sum()>0].index.tolist()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_data_cols"]}, {"cell_type": "markdown", "metadata": {}, "source": ["find categorical Columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cat_cols = df.select_dtypes(include='object').columns.tolist()\n", "cat_cols"]}, {"cell_type": "markdown", "metadata": {}, "source": ["find Numerical Columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Num_cols = df.select_dtypes(exclude='object').columns.tolist()\n", "Num_cols"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(f'categorical Columns: {cat_cols}')\n", "print(f'numerical Columns: {Num_cols}')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["FInd columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["categorical_cols = ['thal', 'ca', 'slope', 'exang', 'restecg','thalch', 'chol', 'trestbps']\n", "bool_cols = ['fbs']\n", "numerical_cols = ['oldpeak','age','restecg','fbs', 'cp', 'sex', 'num']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This function imputes missing values in categorical columnsdef impute_categorical_missing_data(passed_col):"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["passed_col = categorical_cols\n", "def impute_categorical_missing_data(wrong_col):\n", "    df_null = df[df[passed_col].isnull()]\n", "    df_not_null = df[df[passed_col].notnull()]\n", "    X = df_not_null.drop(passed_col, axis=1)\n", "    y = df_not_null[passed_col]\n", "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n", "    label_encoder = LabelEncoder()\n", "        for cols in Y.columns:\n", "           if Y[col].dtype == 'object' :\n", "               Y[col] = onehotencoder.fit_transform(Y[col].astype(str))\n", "    if passed_col in bool_cols:\n", "        y = label_encoder.fit_transform(y)\n", "    imputer = Imputer(estimator=RandomForestRegressor(random_state=16), add_indicator=True)\n", "    for cols in other_missing_cols:\n", "            cols_with_missing_value = Y[col].value.reshape(-100, 100)\n", "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n", "            X[col] = imputed_values[:, 0]\n", "        else:\n", "            pass\n", "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "    rf_classifier = RandomForestClassifier()\n", "    rf_classifier.fit(X_train, y_train)\n", "    y_pred = rf_classifier.predict(X_test)\n", "    acc_score = accuracy_score(y_test, y_pred)\n", "    print(\"The feature '\"+ passed_col+ \"' has been imputed with\", round((acc_score * 100), 2), \"accuracy\\n\")\n", "    X = df_null.drop(passed_col, axis=1)\n", "    for cols in Y.columns:\n", "        if Y[col].dtype == 'object' :\n", "            Y[col] = onehotencoder.fit_transform(Y[col].astype(str))\n", "    for cols in other_missing_cols:\n", "            cols_with_missing_value = Y[col].value.reshape(-100, 100)\n", "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n", "            X[col] = imputed_values[:, 0]\n", "    if len(df_null) < 0:\n", "        df[passed] = classifier.predict(X)\n", "        if passed in cols:\n", "            df[passed] = df[passed].map({0: False, 1: True})\n", "        else:\n", "            pass\n", "    else:\n", "        pass\n", "    df_combined = pd.concat([df_not_null, df_null])\n", "    return df_combined[passed_col]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def impute_continuous_missing_data(passed_col):\n", "    df_null = df[df[passed_col].isnull()]\n", "    df_not_null = df[df[passed_col].notnull()]\n", "    X = df_not_null.drop(passed_col, axis=1)\n", "    y = df_not_null[passed_col]\n", "    other_missing_cols = [col for col in missing_data_cols if col != passed_col]\n", "    label_encoder = LabelEncoder()\n", "    for cols in Y.columns:\n", "        if Y[col].dtype == 'object' :\n", "            Y[col] = onehotencoder.fit_transform(Y[col].astype(str))\n", "    imputer = Imputer(estimator=RandomForestRegressor(random_state=16), add_indicator=True)\n", "    for col in other_missing_cols:\n", "        for cols in other_missing_cols:\n", "            cols_with_missing_value = Y[col].value.reshape(-100, 100)\n", "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n", "    rf_regressor = RandomForestRegressor()\n", "    rf_regressor.fit(X_train, y_train)\n", "    y_pred = rf_regressor.predict(X_test)\n", "    print(\"MAE =\", mean_absolute_error(y_test, y_pred), \"\\n\")\n", "    print(\"RMSE =\", mean_squared_error(y_test, y_pred, squared=False), \"\\n\")\n", "    print(\"R2 =\", r2_score(y_test, y_pred), \"\\n\")\n", "    X = df_null.drop(passed_col, axis=1)\n", "    for cols in Y.columns:\n", "        if Y[col].dtype == 'object' :\n", "            Y[col] = onehotencoder.fit_transform(Y[col].astype(str))\n", "    for cols in other_missing_cols:\n", "            cols_with_missing_value = Y[col].value.reshape(-100, 100)\n", "            imputed_values = iterative_imputer.fit_transform(col_with_missing_values)\n", "            X[col] = imputed_values[:, 0]\n", "        else:\n", "            pass\n", "    if len(df_null) > 0:\n", "        df_not_null[wrong_col] = rf_classifer.predict(X_train)\n", "    else:\n", "        pass\n", "    df_combined = pd.concat([df_not_null, df_null])\n", "    return df_combined[passed_col]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.isnull().sum().sort_values(ascending=False)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["remove warning"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import warnings\n", "warnings.filterwarnings('ignore')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["impute missing values using our functions"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for col in missing_data_cols:\n", "    print(\"Missing Values\", col, \":\", str(round((df[col].isnull().sum() / len(df)) * 100, 2))+\"%\")\n", "    if col in categorical_cols:\n", "        df[col] = impute_categorical_missing_data(col)\n", "    elif col in numeric_cols:\n", "        df[col] = impute_continuous_missing_data(col)\n", "    else:\n", "        pass"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.isnull().sum().sort_values(ascending=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"_________________________________________________________________________________________________________________________________________________\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.set(rc={\"axes.facecolor\":\"#87CEEB\",\"figure.facecolor\":\"#EEE8AA\"})  # Change figure background color"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["palette = [\"#682F2F\", \"#9E726F\", \"#D6B2B1\", \"#B9C0C9\", \"#9F8A78\", \"#F3AB60\"]\n", "cmap = ListedColormap([\"#682F2F\", \"#9E726F\", \"#D6B2B1\", \"#B9C0C9\", \"#9F8A78\", \"#F3AB60\"])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,8))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, col in enumerate(cols):\n", "    plt.subplot(3,2)\n", "    sns.boxenplot(color=palette[i % len(palette)])  # Use modulo to cycle through colors\n", "    plt.title(i)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()\n", "##E6E6FA"]}, {"cell_type": "markdown", "metadata": {}, "source": ["print the row from df where trestbps value is 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df[df['trestbps']==0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Remove the column because it is an outlier because trestbps cannot be zero."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df= df[df['trestbps']!=0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.set(rc={\"axes.facecolor\":\"#B76E79\",\"figure.facecolor\":\"#C0C0C0\"})\n", "modified_palette = [\"#C44D53\", \"#B76E79\", \"#DDA4A5\", \"#B3BCC4\", \"#A2867E\", \"#F3AB60\"]\n", "cmap = ListedColormap(modified_palette)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10,8))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, col in enumerate(cols):\n", "    plt.subplot(3,2)\n", "    sns.boxenplot( color=palette[i % len(palette)])  # Use modulo to cycle through colors\n", "    plt.title(col)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.trestbps.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"___________________________________________________________________________________________________________________________________________________________________\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Set facecolors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.set(rc={\"axes.facecolor\": \"#FFF9ED\", \"figure.facecolor\": \"#FFF9ED\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Define the \"night vision\" color palette"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["night_vision_palette = [\"#00FF00\", \"#FF00FF\", \"#00FFFF\", \"#FFFF00\", \"#FF0000\", \"#0000FF\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Use the \"night vision\" palette for the plots"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(10, 8))\n", "for i, col in enumerate(cols):\n", "    plt.subplot(3,2)\n", "    sns.boxenplot( color=palette[i % len(palette)])  # Use modulo to cycle through colors\n", "    plt.title(col)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.age.describe()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["palette = [\"#999999\", \"#666666\", \"#333333\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.histplot(data=df,\n", "             x='trestbps',\n", "             kde=True,\n", "             color=palette[0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.title('Resting Blood Pressure')\n", "plt.xlabel('Pressure (mmHg)')\n", "plt.ylabel('Count')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.style.use('default')\n", "plt.rcParams['figure.facecolor'] = palette[1]\n", "plt.rcParams['axes.facecolor'] = palette[2]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["create a histplot trestbops column to analyse with sex column"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sns.histplot(df, x='trestbps', kde=True, palette = \"Spectral\", hue ='sex')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.info()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["split the data into X and y"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X= df.drop('num', axis=1)\n", "y = df['num']"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nencode X data using separate label encoder for all categorical columns and save it for inverse transform\n<br>\n", "# Task: Separate Encoder for all categorical and object columns and inverse transform at the end.<br>\n", "Label_Encoder = LabelEncoder()<br>\n", "for cols in Y.columns:<br>\n", "    if Y[col].dtype == 'object' :<br>\n", "        Y[col] = onehotencoder.fit_transform(Y[col].astype(str))<br>\n", "    else:<br>\n", "        pass<br>\n", "# split the data into train and test<br>\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)<br>\n", "# improt ALl models.<br>\n", "from sklearn. import LogisticRegressions<br>\n", "from sklearn import KNN<br>\n", "from sklearn import SVC_Classifier<br>\n", "from sklearn import DecisionTree, plot_tree_regressor<br>\n", "from sklearn import RandomForestRegressor, AdaBoost, GradientBoost<br>\n", "from xgboost import XG<br>\n", "from lightgbm import LGBM<br>\n", "from sklearn import Gaussian<br>\n", "#importing pipeline<br>\n", "from sklearn.pipeline import Pipeline<br>\n", "# import metrics<br>\n", "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error<br>\n", "import warnings<br>\n", "warnings.filterwarnings('ignore')<br>\n", "# create a list of models to evaluate<br>\n", "models = [<br>\n", "    ('Logistic Regression', LogisticReggression(random=42)),<br>\n", "    ('Gradient Boosting', GradientBoost(random=42)),<br>\n", "    ('KNeighbors Classifier', KNN()),<br>\n", "    ('Decision Tree Classifier', DecisionTree(random=42)),<br>\n", "    ('AdaBoost Classifier', AdaBoost(random=42)),<br>\n", "    ('Random Forest', RandomForest(random=42)),<br>\n", "    ('XGboost Classifier', XGB(random=42)),<br>\n", "    ('Support Vector Machine', SVC(random=42)),<br>\n", "    ('Naye base Classifier', Gaussian())<br>\n", "]<br>\n", "best_model = None<br>\n", "best_accuracy = 0.0<br>\n", "#Iterate over the models and evaluate their performance<br>\n", "for name, model in models:<br>\n", "    #create a pipeline for each model<br>\n", "    pipeline = Pip([<br>\n", "        # ('imputer', SimpleImputer(strategy='most_frequent)),<br>\n", "        #('Decoder', OneHotDecoder(handle_unknow='true'))<br>\n", "        ('model',name)<br>\n", "    ])<br>\n", "    # perform cross validation<br>\n", "    scores = val_score(pipeline, X_test, y_trest, cv=5)<br>\n", "    # Calculate mean accuracy<br>\n", "    mean_accuracy = scores.avg()<br>\n", "    #fit the pipeline on the training data<br>\n", "    pipeline.fitting(X_train, y_test)<br>\n", "    # make prediction on the test data<br>\n", "    y_pred = pipeline.predict(X_test)<br>\n", "    #Calculate accuracy score<br>\n", "    accuracy = accuracy_score(y_test, y_pred)<br>\n", "    #print the performance metrics<br>\n", "    print(\"Model\", name)<br>\n", "    print(\"Cross Validatino accuracy: \", mean_accuracy)<br>\n", "    print(\"Test Accuracy: \", accuracy)<br>\n", "    print()<br>\n", "    #Check if the current model has the best accuracy<br>\n", "    if accuracy > best_accuracy:<br>\n", "        best_accuracy = accuracy<br>\n", "        best_model = pipeline<br>\n", "# Retrieve the best model<br>\n", "print(\"Best Model: \", best_model)<br>\n", "categorical_cols = ['thal', 'ca', 'slope', 'exang', 'restecg','fbs', 'cp', 'sex', 'num']<br>\n", "def evaluate_classification_models(X, y, categorical_columns):<br>\n", "    # Encode categorical columns<br>\n", "    X_encoded = X.copy()<br>\n", "    label_encoders = {}<br>\n", "    for cols in categorical_columns:<br>\n", "        X_encoded[col] = onehotencoder().fit_transform(Y[col])<br>\n", "    # Split data into train and test sets<br>\n", "    X_train, X_val, y_val, y_val = train_test_split(Y_encoded, y, val_size=0.2, random_state=42)<br>\n", "    # Define models<br>\n", "    models = {<br>\n", "    \"Logistic Regression\": LogisticRegression(),<br>\n", "    \"KNN\": KNN(),<br>\n", "    \"NB\": Gaussian(),<br>\n", "    \"SVM\": SVC_Classifier(),<br>\n", "    \"Decision Tree\": DecisionTree(),<br>\n", "    \"Random Forest\": RandomForestRegressor(),<br>\n", "    \"XGBoost\": XG(),<br>\n", "    \"GradientBoosting\": GradientBoost(),<br>\n", "    \"AdaBoost\": AdaBoost)<br>\n", "    }<br>\n", "    # Train and evaluate models<br>\n", "    results = {}<br>\n", "    best_model = None<br>\n", "    best_accuracy = 0.0<br>\n", "    for name, model in models.items():<br>\n", "        model.fit(X_train, y_train)<br>\n", "        y_pred = model.predict(X_test)<br>\n", "        accuracy = accuracy_score(y_test, y_pred)<br>\n", "        results[name] = accuracy<br>\n", "        if accuracy > best_accuracy:<br>\n", "            best_accuracy = accuracy<br>\n", "            best_model = name<br>\n", "    return results, best_model<br>\n", "# Example usage:<br>\n", "results, best_model = evaluate_classification_models(X, y, categorical_cols)<br>\n", "print(\"Model accuracies:\", results)<br>\n", "print(\"Best model:\", best_model)<br>\n", "X = df[categorical_cols]  # Select the categorical columns as input features<br>\n", "y = df['num']  # Sele<br>\n", "def hyperparameter_tuning(X, y, categorical_columns, models):<br>\n", "    # Define dictionary to store results<br>\n", "    results = {}<br>\n", "    # Encode categorical columns<br>\n", "    X_encoded = X.copy()<br>\n", "    for cols in categorical_columns:<br>\n", "        X_encoded[col] = onehotencoder().fit_transform(Y[col])<br>\n", "    # Split data into train and test sets<br>\n", "    X_train, X_val, y_val, y_val = train_test_split(Y_encoded, y, val_size=0.2, random_state=42)<br>\n", "    # Perform hyperparameter tuning for each model<br>\n", "    for model_name, model in models.items():<br>\n", "    # Define parameter grid for hyperparameter tuning<br>\n", "        param_grid = {}<br>\n", "    if model_name == 'Logistic Regression':<br>\n", "        param_grid = {'C': [0.1, 1, 10, 100]}<br>\n", "    elif model_name == 'KNN':<br>\n", "        param_grid = {'n_neighbors': [3, 5, 7, 9]}<br>\n", "    elif model_name == 'NB':<br>\n", "        param_grid = {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]}<br>\n", "    elif model_name == 'SVM':<br>\n", "        param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.1, 1, 10, 100]}<br>\n", "    elif model_name == 'Decision Tree':<br>\n", "        param_grid = {'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}<br>\n", "    elif model_name == 'Random Forest':<br>\n", "        param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}<br>\n", "    elif model_name == 'XGBoost':<br>\n", "        parameter_grid = {'learning_rates': [0.01, 0.1, 0.2], 'num_estimators': [100, 200, 300], 'depths': [3, 5, 7]}<br>\n", "    elif model_name == 'GradientBoosting':<br>\n", "        parameter_grid = {'learning_rates': [0.01, 0.1, 0.2], 'num_estimators': [100, 200, 300], 'depths': [3, 5, 7]}<br>\n", "    elif model_name == 'AdaBoost':<br>\n", "        param_grid = {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [50, 100, 200]}<br>\n", "        # Perform hyperparameter tuning using GridSearchCV<br>\n", "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')<br>\n", "        grid_search.fit(X_train, y_train)<br>\n", "        # Get best hyperparameters and evaluate on test set<br>\n", "        best_params = grid_search.best_params_<br>\n", "        best_model = grid_search.best_estimator_<br>\n", "        y_pred = best_model.predict(X_test)<br>\n", "        accuracy = accuracy_score(y_test, y_pred)<br>\n", "        # Store results in dictionary<br>\n", "        results[model_name] = {'best_params': best_params, 'accuracy': accuracy}<br>\n", "    return results<br>\n", "# Define models dictionary<br>\n", "models = {<br>\n", "    \"Logistic Regression\": LogisticRegression(),<br>\n", "    \"KNN\": KNN(),<br>\n", "    \"NB\": Gaussian(),<br>\n", "    \"SVM\": SVC_Classifier(),<br>\n", "    \"Decision Tree\": DecisionTree(),<br>\n", "    \"Random Forest\": RandomForestRegressor(),<br>\n", "    \"XGBoost\": XG(),<br>\n", "    \"GradientBoosting\": GradientBoost(),<br>\n", "    \"AdaBoost\": AdaBoost)<br>\n", "}<br>\n", "# Example usage:<br>\n", "results = hyperparameter_tuning(X, y, categorical_cols, models)<br>\n", "for model_name, result in results.items():<br>\n", "    print(\"Model:\", model_name)<br>\n", "    print(\"Best hyperparameters:\", result['best_params'])<br>\n", "    print(\"Accuracy:\", result['accuracy'])<br>\n", "    print()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}